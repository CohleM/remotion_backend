{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f4e3d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width: 1920, Height: 1080, FPS: 30, duration: 1800.04825 seconds\n"
     ]
    }
   ],
   "source": [
    "import ffmpeg\n",
    "\n",
    "probe = ffmpeg.probe('input1.mp4')\n",
    "video_info = next(s for s in probe['streams'] if s['codec_type'] == 'video')\n",
    "\n",
    "width = int(video_info['width'])\n",
    "height = int(video_info['height'])\n",
    "video_info = next(s for s in probe['streams'] if s['codec_type'] == 'video')\n",
    "duration = float(video_info['duration'])\n",
    "fps = 30\n",
    "\n",
    "print(f\"Width: {width}, Height: {height}, FPS: {fps}, duration: {duration} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1a3543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 1800.04825 seconds\n"
     ]
    }
   ],
   "source": [
    "import ffmpeg\n",
    "\n",
    "probe = ffmpeg.probe('input1.mp4')\n",
    "\n",
    "\n",
    "print(f\"Duration: {duration} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf8da9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "video = cv2.VideoCapture('video.mp4')\n",
    "\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "duration = frame_count / fps\n",
    "\n",
    "video.release()\n",
    "\n",
    "print(f\"Duration: {duration} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ce3a63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 8.0 Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with Apple clang version 16.0.0 (clang-1600.0.26.6)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/8.0_1 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      60.  8.100 / 60.  8.100\n",
      "  libavcodec     62. 11.100 / 62. 11.100\n",
      "  libavformat    62.  3.100 / 62.  3.100\n",
      "  libavdevice    62.  1.100 / 62.  1.100\n",
      "  libavfilter    11.  4.100 / 11.  4.100\n",
      "  libswscale      9.  1.100 /  9.  1.100\n",
      "  libswresample   6.  1.100 /  6.  1.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'input1.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf62.3.100\n",
      "  Duration: 00:30:00.05, start: 0.000000, bitrate: 1077 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 1920x1080 [SAR 1:1 DAR 16:9], 943 kb/s, 23.98 fps, 23.98 tbr, 24k tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : ISO Media file produced by Google Inc.\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1[0x2](eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : ISO Media file produced by Google Inc.\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> h264 (libx264))\n",
      "  Stream #0:1 -> #0:1 (aac (native) -> aac (native))\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x12d0106a0] using SAR=1/1\n",
      "[libx264 @ 0x12d0106a0] using cpu capabilities: ARMv8 NEON DotProd\n",
      "[libx264 @ 0x12d0106a0] profile High, level 3.0, 4:2:0, 8-bit\n",
      "[libx264 @ 0x12d0106a0] 264 - core 165 r3222 b35605a - H.264/MPEG-4 AVC codec - Copyleft 2003-2025 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=11 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=23 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'input1_360p.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf62.3.100\n",
      "  Stream #0:0(und): Video: h264 (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 640x360 [SAR 1:1 DAR 16:9], q=2-31, 23.98 fps, 24k tbn (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc62.11.100 libx264\n",
      "      handler_name    : ISO Media file produced by Google Inc.\n",
      "      vendor_id       : [0][0][0][0]\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "  Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc62.11.100 aac\n",
      "      handler_name    : ISO Media file produced by Google Inc.\n",
      "      vendor_id       : [0][0][0][0]\n",
      "frame=43030 fps=503 q=28.0 size=   76800KiB time=00:29:54.62 bitrate= 350.6kbits/s speed=  21x elapsed=0:01:25.62    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video successfully converted to 360p: input1_360p.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[out#0/mp4 @ 0x12be28b80] video:49072KiB audio:28001KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 1.738721%\n",
      "frame=43158 fps=503 q=-1.0 Lsize=   78414KiB time=00:29:59.96 bitrate= 356.9kbits/s speed=  21x elapsed=0:01:25.82    \n",
      "[libx264 @ 0x12d0106a0] frame I:288   Avg QP:17.78  size: 41496\n",
      "[libx264 @ 0x12d0106a0] frame P:13305 Avg QP:21.58  size:  2078\n",
      "[libx264 @ 0x12d0106a0] frame B:29565 Avg QP:29.01  size:   360\n",
      "[libx264 @ 0x12d0106a0] consecutive B-frames:  5.0%  9.0%  6.3% 79.7%\n",
      "[libx264 @ 0x12d0106a0] mb I  I16..4:  3.3% 53.9% 42.8%\n",
      "[libx264 @ 0x12d0106a0] mb P  I16..4:  0.1%  0.8%  0.4%  P16..4: 13.6%  7.3%  5.5%  0.0%  0.0%    skip:72.3%\n",
      "[libx264 @ 0x12d0106a0] mb B  I16..4:  0.0%  0.1%  0.0%  B16..8: 12.5%  1.6%  0.4%  direct: 0.3%  skip:85.1%  L0:39.9% L1:52.2% BI: 7.9%\n",
      "[libx264 @ 0x12d0106a0] 8x8 transform intra:57.6% inter:62.1%\n",
      "[libx264 @ 0x12d0106a0] coded y,uvDC,uvAC intra: 86.3% 87.3% 66.7% inter: 3.9% 2.8% 0.2%\n",
      "[libx264 @ 0x12d0106a0] i16 v,h,dc,p: 26% 24%  6% 44%\n",
      "[libx264 @ 0x12d0106a0] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 25% 21% 11%  5%  7%  7%  9%  7%  9%\n",
      "[libx264 @ 0x12d0106a0] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 27% 22%  8%  5%  8%  8%  9%  6%  7%\n",
      "[libx264 @ 0x12d0106a0] i8c dc,h,v,p: 38% 22% 31% 10%\n",
      "[libx264 @ 0x12d0106a0] Weighted P-Frames: Y:0.3% UV:0.2%\n",
      "[libx264 @ 0x12d0106a0] ref P L0: 64.0% 17.1% 11.5%  7.4%  0.0%\n",
      "[libx264 @ 0x12d0106a0] ref B L0: 88.1%  8.5%  3.4%\n",
      "[libx264 @ 0x12d0106a0] ref B L1: 94.5%  5.5%\n",
      "[libx264 @ 0x12d0106a0] kb/s:223.32\n",
      "[aac @ 0x12be671c0] Qavg: 589.732\n"
     ]
    }
   ],
   "source": [
    "from convert_to_audio import convert_video\n",
    "\n",
    "convert_video(\"input1.mp4\", target_height=360)  # 360p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf68c73",
   "metadata": {},
   "source": [
    "The quick brown fox leaps over the sleepy dog while bright birds chatter in tall green trees under a warm golden sunset, as a gentle breeze carries the scent of fresh grass across the quiet countryside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ddc8b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/cohlem/Projects/Experimentation/remotion_backend/subtitle_generator'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1d7ec87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update subtitle_generator/utils/hybrid_line_divider.py\n",
    "import re\n",
    "import logging\n",
    "import random\n",
    "from typing import List, Dict, Optional, Tuple, Any, Literal\n",
    "from models import (\n",
    "    GroupWithHighlight, \n",
    "    SubtitleGroup, \n",
    "    SubtitleLine,\n",
    "    FontConfig, GroupDivisionWithHighlights, SubtitleTimeline\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class HybridLineDivider:\n",
    "    \"\"\"\n",
    "    Rule-based line divider for hybrid subtitle processing.\n",
    "    Divides groups into lines using highlight word as anchor.\n",
    "    Supports configurable fonts per style.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_words_per_line: int = 3, font_config: Optional[FontConfig] = None):\n",
    "        self.max_words = max_words_per_line\n",
    "        self.font_config = font_config or FontConfig()  # Default to normal only\n",
    "        random.seed()  # Initialize random for font selection\n",
    "    \n",
    "    def divide_group(self, group: GroupWithHighlight) -> SubtitleGroup:\n",
    "        \"\"\"\n",
    "        Divide a single group into lines based on highlight word and font config.\n",
    "        \"\"\"\n",
    "        text = group.group_text\n",
    "        highlight = group.highlight_word\n",
    "        \n",
    "        # If no highlight or highlight not in text, treat as normal group\n",
    "        if not highlight or highlight not in text:\n",
    "            return self._divide_without_highlight(text)\n",
    "        \n",
    "        # Split text into words preserving order\n",
    "        words = text.split()\n",
    "        \n",
    "        # Find highlight position\n",
    "        try:\n",
    "            clean_words = [self._clean_word(w) for w in words]\n",
    "            clean_highlight = self._clean_word(highlight)\n",
    "            highlight_idx = clean_words.index(clean_highlight)\n",
    "        except ValueError:\n",
    "            logger.warning(f\"Highlight word '{highlight}' not found in '{text}'\")\n",
    "            return self._divide_without_highlight(text)\n",
    "        \n",
    "        # Split into before and after highlight\n",
    "        before_words = words[:highlight_idx]\n",
    "        after_words = words[highlight_idx + 1:]\n",
    "        \n",
    "        # Build lines\n",
    "        lines = []\n",
    "        \n",
    "        # Get fonts from config\n",
    "        highlight_font = self.font_config.get_highlight_font()\n",
    "        supporting_fonts = self.font_config.get_supporting_fonts()  # Get list of available supporting fonts\n",
    "        \n",
    "\n",
    "        print('supporting fonts', supporting_fonts)\n",
    "        # Handle before highlight - split into chunks of max_words\n",
    "        # Alternate between available supporting fonts\n",
    "        if before_words:\n",
    "            before_chunks = self._chunk_words(before_words, self.max_words)\n",
    "            for i, chunk in enumerate(before_chunks):\n",
    "                # Cycle through supporting fonts: 0, 1, 0, 1, etc.\n",
    "                font_idx = i % len(supporting_fonts)\n",
    "                print('before words chunk', chunk, supporting_fonts[font_idx])\n",
    "                lines.append(SubtitleLine(\n",
    "                    text=\" \".join(chunk),\n",
    "                    font_type=supporting_fonts[font_idx]\n",
    "                ))\n",
    "        \n",
    "        # Add highlight line with configured highlight font (bold or italic)\n",
    "        lines.append(SubtitleLine(\n",
    "            text=highlight,\n",
    "            font_type=highlight_font\n",
    "        ))\n",
    "        \n",
    "        # Handle after highlight - split into chunks of max_words\n",
    "        # Continue alternating pattern from where we left off\n",
    "        if after_words:\n",
    "            after_chunks = self._chunk_words(after_words, self.max_words)\n",
    "            start_idx = len(before_chunks) % len(supporting_fonts) if before_words else 0\n",
    "            for i, chunk in enumerate(after_chunks):\n",
    "                font_idx = (start_idx + i) % len(supporting_fonts)\n",
    "\n",
    "                print('after words chunk', chunk, supporting_fonts[font_idx])\n",
    "                lines.append(SubtitleLine(\n",
    "                    text=\" \".join(chunk),\n",
    "                    font_type=supporting_fonts[font_idx]\n",
    "                ))\n",
    "        \n",
    "        # Ensure we don't exceed 3 lines total\n",
    "        lines = self._optimize_lines(lines, supporting_fonts)\n",
    "        \n",
    "        return SubtitleGroup(\n",
    "            group_text=text,\n",
    "            lines=lines\n",
    "        )\n",
    "    \n",
    "    def _clean_word(self, word: str) -> str:\n",
    "        \"\"\"Remove punctuation for matching.\"\"\"\n",
    "        return re.sub(r'[^\\w\\s]', '', word.lower()).strip()\n",
    "    \n",
    "    def _chunk_words(self, words: List[str], max_size: int) -> List[List[str]]:\n",
    "        \"\"\"Split word list into chunks of max_size.\"\"\"\n",
    "        if not words:\n",
    "            return []\n",
    "        \n",
    "        chunks = []\n",
    "        current_chunk = []\n",
    "        \n",
    "        for word in words:\n",
    "            if len(current_chunk) >= max_size:\n",
    "                chunks.append(current_chunk)\n",
    "                current_chunk = []\n",
    "            current_chunk.append(word)\n",
    "        \n",
    "        if current_chunk:\n",
    "            chunks.append(current_chunk)\n",
    "        \n",
    "        return chunks\n",
    "    \n",
    "    def _divide_without_highlight(self, text: str) -> SubtitleGroup:\n",
    "        \"\"\"Divide group without highlight word (all supporting fonts).\"\"\"\n",
    "        words = text.split()\n",
    "        \n",
    "        # Simple chunking\n",
    "        chunks = self._chunk_words(words, self.max_words)\n",
    "        \n",
    "        supporting_fonts = self.font_config.get_supporting_fonts()\n",
    "        \n",
    "        # Alternate between supporting fonts\n",
    "        lines = []\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            font_idx = i % len(supporting_fonts)\n",
    "            lines.append(SubtitleLine(\n",
    "                text=\" \".join(chunk), \n",
    "                font_type=supporting_fonts[font_idx]\n",
    "            ))\n",
    "        \n",
    "        return SubtitleGroup(group_text=text, lines=lines)\n",
    "    \n",
    "    def _optimize_lines(self, lines: List[SubtitleLine], supporting_fonts: List[str]) -> List[SubtitleLine]:\n",
    "        \"\"\"\n",
    "        Ensure we have at most 3 lines.\n",
    "        If more than 3, merge supporting lines intelligently while alternating fonts.\n",
    "        \"\"\"\n",
    "        if len(lines) <= 3:\n",
    "            return lines\n",
    "        \n",
    "        # Find highlight line index\n",
    "        highlight_font = self.font_config.get_highlight_font()\n",
    "        highlight_idx = None\n",
    "        \n",
    "        for i, line in enumerate(lines):\n",
    "            if line.font_type == highlight_font:\n",
    "                highlight_idx = i\n",
    "                break\n",
    "        \n",
    "        if highlight_idx is None:\n",
    "            # No highlight found, just take first 3 chunks with alternating fonts\n",
    "            result = []\n",
    "            for i in range(min(3, len(lines))):\n",
    "                font_idx = i % len(supporting_fonts)\n",
    "                result.append(SubtitleLine(text=lines[i].text, font_type=supporting_fonts[font_idx]))\n",
    "            return result\n",
    "        \n",
    "        # Strategy: Keep highlight line, merge others\n",
    "        before = lines[:highlight_idx]\n",
    "        highlight = lines[highlight_idx]\n",
    "        after = lines[highlight_idx + 1:]\n",
    "        \n",
    "        # Merge strategy: reduce to max 1 line before and 1 line after\n",
    "        while len(before) > 1 and len(after) > 1:\n",
    "            if len(before) >= len(after):\n",
    "                # Merge last two before lines - use the font of the first one to maintain alternation pattern\n",
    "                merged_text = before[-2].text + \" \" + before[-1].text\n",
    "                before[-2] = SubtitleLine(text=merged_text, font_type=before[-2].font_type)\n",
    "                before.pop(-1)\n",
    "            else:\n",
    "                # Merge first two after lines\n",
    "                merged_text = after[0].text + \" \" + after[1].text\n",
    "                after[0] = SubtitleLine(text=merged_text, font_type=after[0].font_type)\n",
    "                after.pop(1)\n",
    "        \n",
    "        # If still over 3 lines, merge all extras into adjacent lines\n",
    "        while len(before) + 1 + len(after) > 3:\n",
    "            if len(before) > 1:\n",
    "                # Merge last two before\n",
    "                merged_text = before[-2].text + \" \" + before[-1].text\n",
    "                before[-2] = SubtitleLine(text=merged_text, font_type=before[-2].font_type)\n",
    "                before.pop(-1)\n",
    "            elif len(after) > 1:\n",
    "                # Merge first two after\n",
    "                merged_text = after[0].text + \" \" + after[1].text\n",
    "                after[0] = SubtitleLine(text=merged_text, font_type=after[0].font_type)\n",
    "                after.pop(1)\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        # Ensure alternating fonts for final result if we have 2 supporting lines\n",
    "        result = before + [highlight] + after\n",
    "        if len(result) == 3 and len(supporting_fonts) >= 2:\n",
    "            # Check if both supporting lines have same font\n",
    "            supporting_indices = [i for i, line in enumerate(result) if line.font_type != highlight_font]\n",
    "            if len(supporting_indices) == 2:\n",
    "                idx1, idx2 = supporting_indices\n",
    "                if result[idx1].font_type == result[idx2].font_type:\n",
    "                    # They have same font, change second one to alternate\n",
    "                    current_font = result[idx1].font_type\n",
    "                    alternate_font = supporting_fonts[1] if current_font == supporting_fonts[0] else supporting_fonts[0]\n",
    "                    result[idx2] = SubtitleLine(text=result[idx2].text, font_type=alternate_font)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def divide_groups(self, groups: List[GroupWithHighlight]) -> List[SubtitleGroup]:\n",
    "        \"\"\"Process multiple groups.\"\"\"\n",
    "        return [self.divide_group(g) for g in groups]\n",
    "\n",
    "\n",
    "class HybridPostProcessor:\n",
    "    \"\"\"\n",
    "    Post-process groups with highlights, splitting oversized groups\n",
    "    and correctly assigning highlight words to split parts.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_words_per_group: int = 8):\n",
    "        self.max_words = max_words_per_group\n",
    "    \n",
    "    def process(\n",
    "        self, \n",
    "        division: 'GroupDivisionWithHighlights'\n",
    "    ) -> List[GroupWithHighlight]:\n",
    "        \"\"\"\n",
    "        Split oversized groups and assign highlight words correctly.\n",
    "        \"\"\"\n",
    "        # from subtitle_generator.models import GroupDivisionWithHighlights\n",
    "        \n",
    "        result = []\n",
    "        \n",
    "        for group in division.groups:\n",
    "            word_count = len(group.group_text.split())\n",
    "            \n",
    "            if word_count <= self.max_words:\n",
    "                result.append(group)\n",
    "            else:\n",
    "                # Split and distribute highlight\n",
    "                split_groups = self._split_group_with_highlight(group)\n",
    "                result.extend(split_groups)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _split_group_with_highlight(\n",
    "        self, \n",
    "        group: GroupWithHighlight\n",
    "    ) -> List[GroupWithHighlight]:\n",
    "        \"\"\"\n",
    "        Split oversized group and determine which part gets the highlight.\n",
    "        \"\"\"\n",
    "        words = group.group_text.split()\n",
    "        highlight = group.highlight_word\n",
    "        \n",
    "        # Find highlight position\n",
    "        try:\n",
    "            clean_words = [re.sub(r'[^\\w]', '', w.lower()) for w in words]\n",
    "            clean_highlight = re.sub(r'[^\\w]', '', highlight.lower()) if highlight else \"\"\n",
    "            highlight_idx = clean_words.index(clean_highlight) if clean_highlight else -1\n",
    "        except ValueError:\n",
    "            highlight_idx = -1\n",
    "        \n",
    "        # Calculate split point\n",
    "        total_words = len(words)\n",
    "        mid_point = total_words // 2\n",
    "        \n",
    "        # Adjust split to not break in middle of a potential highlight\n",
    "        split_point = mid_point\n",
    "        \n",
    "        # Split words\n",
    "        first_half = words[:split_point]\n",
    "        second_half = words[split_point:]\n",
    "        \n",
    "        first_text = \" \".join(first_half)\n",
    "        second_text = \" \".join(second_half)\n",
    "        \n",
    "        # Determine which half gets the highlight\n",
    "        first_highlight = None\n",
    "        second_highlight = None\n",
    "        \n",
    "        if highlight_idx >= 0 and highlight_idx < split_point:\n",
    "            # Highlight is in first half\n",
    "            first_highlight = highlight\n",
    "            # Try to find a secondary highlight in second half (longest word)\n",
    "            if len(second_half) > 1:\n",
    "                second_highlight = max(second_half, key=len)\n",
    "        elif highlight_idx >= split_point:\n",
    "            # Highlight is in second half\n",
    "            second_highlight = highlight\n",
    "            # Try to find secondary in first half\n",
    "            if len(first_half) > 1:\n",
    "                first_highlight = max(first_half, key=len)\n",
    "        else:\n",
    "            # No highlight found, assign longest words\n",
    "            if len(first_half) > 1:\n",
    "                first_highlight = max(first_half, key=len)\n",
    "            if len(second_half) > 1:\n",
    "                second_highlight = max(second_half, key=len)\n",
    "        \n",
    "        result = []\n",
    "        \n",
    "        if first_half:\n",
    "            result.append(GroupWithHighlight(\n",
    "                group_text=first_text,\n",
    "                highlight_word=first_highlight\n",
    "            ))\n",
    "        \n",
    "        if second_half:\n",
    "            result.append(GroupWithHighlight(\n",
    "                group_text=second_text,\n",
    "                highlight_word=second_highlight\n",
    "            ))\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def process_divisions(\n",
    "        self, \n",
    "        divisions: List['GroupDivisionWithHighlights']\n",
    "    ) -> List[List[GroupWithHighlight]]:\n",
    "        \"\"\"Process multiple divisions (one per chunk).\"\"\"\n",
    "        return [self.process(d) for d in divisions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc357422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[GroupWithHighlight(group_text=\"one I've met\", highlight_word='met'),\n",
       "  GroupWithHighlight(group_text='So in this video I am going to show you yes i am', highlight_word='video'),\n",
       "  GroupWithHighlight(group_text=\"hehe something you have and im testing it a lot more never's seen\", highlight_word='something'),\n",
       "  GroupWithHighlight(group_text='I want to share', highlight_word='share'),\n",
       "  GroupWithHighlight(group_text='10 of my top tips', highlight_word='tips'),\n",
       "  GroupWithHighlight(group_text='for reading more consistently', highlight_word='reading'),\n",
       "  GroupWithHighlight(group_text='And if you follow', highlight_word='follow'),\n",
       "  GroupWithHighlight(group_text='the tips in this video', highlight_word='tips'),\n",
       "  GroupWithHighlight(group_text=\"then there's a high chance\", highlight_word='chance'),\n",
       "  GroupWithHighlight(group_text='you might even be able', highlight_word='able'),\n",
       "  GroupWithHighlight(group_text='to read a hundred books a year', highlight_word='read'),\n",
       "  GroupWithHighlight(group_text='but', highlight_word=None)]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "divisions_with_highlights = [GroupDivisionWithHighlights(groups=[GroupWithHighlight(group_text=\"one I've met\", highlight_word='met'), \n",
    "GroupWithHighlight(group_text=\"So in this video I am going to show you yes i am hehe something you have and im testing it a lot more never's seen\", highlight_word=None), \n",
    "GroupWithHighlight(group_text='I want to share', highlight_word='share'), \n",
    "GroupWithHighlight(group_text='10 of my top tips', highlight_word='tips'), \n",
    "GroupWithHighlight(group_text='for reading more consistently', highlight_word='reading'), \n",
    "GroupWithHighlight(group_text='And if you follow', highlight_word='follow'), \n",
    "GroupWithHighlight(group_text='the tips in this video', highlight_word='tips'), \n",
    "GroupWithHighlight(group_text=\"then there's a high chance\", highlight_word='chance'), \n",
    "GroupWithHighlight(group_text='you might even be able', highlight_word='able'), \n",
    "GroupWithHighlight(group_text='to read a hundred books a year', highlight_word='read'), \n",
    "GroupWithHighlight(group_text='but', highlight_word=None)])]\n",
    "\n",
    "\n",
    "\n",
    "post_processor = HybridPostProcessor(max_words_per_group=8)\n",
    "line_divider = HybridLineDivider(max_words_per_line=3, font_config=FontConfig(normal=True, bold=True, italic=True))\n",
    "\n",
    "processed_groups_per_chunk = post_processor.process_divisions(divisions_with_highlights)\n",
    "\n",
    "processed_groups_per_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2684681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supporting fonts ['normal', 'italic']\n",
      "before words chunk ['one', \"I've\"] normal\n",
      "supporting fonts ['normal', 'italic']\n",
      "before words chunk ['So', 'in', 'this'] normal\n",
      "after words chunk ['I', 'am', 'going'] italic\n",
      "after words chunk ['to', 'show', 'you'] normal\n",
      "after words chunk ['yes', 'i', 'am'] italic\n",
      "supporting fonts ['normal', 'italic']\n",
      "before words chunk ['hehe'] normal\n",
      "after words chunk ['you', 'have', 'and'] italic\n",
      "after words chunk ['im', 'testing', 'it'] normal\n",
      "after words chunk ['a', 'lot', 'more'] italic\n",
      "after words chunk [\"never's\", 'seen'] normal\n",
      "supporting fonts ['normal', 'italic']\n",
      "before words chunk ['I', 'want', 'to'] normal\n",
      "supporting fonts ['normal', 'italic']\n",
      "before words chunk ['10', 'of', 'my'] normal\n",
      "before words chunk ['top'] italic\n",
      "supporting fonts ['normal', 'italic']\n",
      "before words chunk ['for'] normal\n",
      "after words chunk ['more', 'consistently'] italic\n",
      "supporting fonts ['normal', 'italic']\n",
      "before words chunk ['And', 'if', 'you'] normal\n",
      "supporting fonts ['normal', 'italic']\n",
      "before words chunk ['the'] normal\n",
      "after words chunk ['in', 'this', 'video'] italic\n",
      "supporting fonts ['normal', 'italic']\n",
      "before words chunk ['then', \"there's\", 'a'] normal\n",
      "before words chunk ['high'] italic\n",
      "supporting fonts ['normal', 'italic']\n",
      "before words chunk ['you', 'might', 'even'] normal\n",
      "before words chunk ['be'] italic\n",
      "supporting fonts ['normal', 'italic']\n",
      "before words chunk ['to'] normal\n",
      "after words chunk ['a', 'hundred', 'books'] italic\n",
      "after words chunk ['a', 'year'] normal\n"
     ]
    }
   ],
   "source": [
    "timelines = []\n",
    "for chunk_idx, chunk_groups in enumerate(processed_groups_per_chunk):\n",
    "    subtitle_groups = line_divider.divide_groups(chunk_groups)\n",
    "    timeline = SubtitleTimeline(timeline=subtitle_groups)\n",
    "    timelines.append(timeline)\n",
    "    logger.info(f\"[Chunk {chunk_idx}] Divided into {len(subtitle_groups)} subtitle groups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8d8fa3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SubtitleGroup(group_text=\"one I've met\", lines=[SubtitleLine(text=\"one I've\", font_type='normal'), SubtitleLine(text='met', font_type='bold')], id=None, start=None, end=None),\n",
       " SubtitleGroup(group_text='So in this video I am going to show you yes i am', lines=[SubtitleLine(text='So in this', font_type='normal'), SubtitleLine(text='video', font_type='bold'), SubtitleLine(text='I am going to show you yes i am', font_type='italic')], id=None, start=None, end=None),\n",
       " SubtitleGroup(group_text=\"hehe something you have and im testing it a lot more never's seen\", lines=[SubtitleLine(text='hehe', font_type='normal'), SubtitleLine(text='something', font_type='bold'), SubtitleLine(text=\"you have and im testing it a lot more never's seen\", font_type='italic')], id=None, start=None, end=None),\n",
       " SubtitleGroup(group_text='I want to share', lines=[SubtitleLine(text='I want to', font_type='normal'), SubtitleLine(text='share', font_type='bold')], id=None, start=None, end=None),\n",
       " SubtitleGroup(group_text='10 of my top tips', lines=[SubtitleLine(text='10 of my', font_type='normal'), SubtitleLine(text='top', font_type='italic'), SubtitleLine(text='tips', font_type='bold')], id=None, start=None, end=None),\n",
       " SubtitleGroup(group_text='for reading more consistently', lines=[SubtitleLine(text='for', font_type='normal'), SubtitleLine(text='reading', font_type='bold'), SubtitleLine(text='more consistently', font_type='italic')], id=None, start=None, end=None),\n",
       " SubtitleGroup(group_text='And if you follow', lines=[SubtitleLine(text='And if you', font_type='normal'), SubtitleLine(text='follow', font_type='bold')], id=None, start=None, end=None),\n",
       " SubtitleGroup(group_text='the tips in this video', lines=[SubtitleLine(text='the', font_type='normal'), SubtitleLine(text='tips', font_type='bold'), SubtitleLine(text='in this video', font_type='italic')], id=None, start=None, end=None),\n",
       " SubtitleGroup(group_text=\"then there's a high chance\", lines=[SubtitleLine(text=\"then there's a\", font_type='normal'), SubtitleLine(text='high', font_type='italic'), SubtitleLine(text='chance', font_type='bold')], id=None, start=None, end=None),\n",
       " SubtitleGroup(group_text='you might even be able', lines=[SubtitleLine(text='you might even', font_type='normal'), SubtitleLine(text='be', font_type='italic'), SubtitleLine(text='able', font_type='bold')], id=None, start=None, end=None),\n",
       " SubtitleGroup(group_text='to read a hundred books a year', lines=[SubtitleLine(text='to', font_type='normal'), SubtitleLine(text='read', font_type='bold'), SubtitleLine(text='a hundred books a year', font_type='italic')], id=None, start=None, end=None),\n",
       " SubtitleGroup(group_text='but', lines=[SubtitleLine(text='but', font_type='normal')], id=None, start=None, end=None)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timelines[0].timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aad770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0691f999",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subtitle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
